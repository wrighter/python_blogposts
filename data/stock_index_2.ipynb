{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65d8c828",
   "metadata": {},
   "source": [
    "# Matching messy data between data sources with Python  \n",
    "Data is often messy and rarely in perfect shape. This is especially true if the data comes from many different sources and the specifications are loosely defined. If your data is in great shape, it's probably because someone else did the dirty work of validating it, cleaning it up, and normalizing it for you.\n",
    "\n",
    "One particular type of problem is matching data between data sources when exact identifiers are missing. This situation has come up for me quite often.\n",
    "\n",
    "When you need to match data, there are a number of techniques that can help. The best way to illustrate this is with a concrete example. To do this, we'll pull data from the SEC's EDGAR system. You can read the [initial article](https://www.wrighters.io/an-introduction-to-accessing-financial-data-in-edgar-using-python/) to learn how to connect to EDGAR and fetch data, and [another article](https://www.wrighters.io/finding-and-analyzing-free-stock-index-data-with-python-and-edgar/) to learn about stock index data in EDGAR. In this article, we'll use some of the stock index data to demonstrate some matching techniques.\n",
    "\n",
    "In this article, we'll look at multiple ways to try to match data between two data sources. In our case, it will be a company name. We'll use the following techniques:\n",
    "1. Merging with exact data\n",
    "1. Cleaning data with a regular expression (and then trying to match again)\n",
    "1. Picking the best data with duplicates using `groupby`\n",
    "1. Fuzzy searching\n",
    "1. Good old manual verification and cleanup\n",
    "\n",
    "## A quick review\n",
    "If you don't want to read the earlier articles, I'll give you a very quick summary of how we got to this point. We found a filing on EDGAR that contains all the investments in an ETF. That filing has an XML document that lists the investments, and if we pick an ETF that tracks a stock index, we can use that filing to build the index holdings. At this point, we want to match the index holding up with all of their other data that is stored in EDGAR. This will allow us to build a rich database of information about all the stocks in an index, for free.\n",
    "\n",
    "## The problem\n",
    "Once we dig into the data, we will start to recognize the problem. The stocks that are held by the ETF are listed by name and CUSIP. We need to figure out how to match the investments in the N-PORT document to EDGAR's internal system for tracking companies, using other identifiers. But all we have to match on is the name.\n",
    "\n",
    "## What we'll learn\n",
    "Along the way, we will learn a few things about dealing with messy data.  If you happen to like financial data, you'll also learn a bit more about how EDGAR works and its internal data. If your domain is outside of finance, the techniques will still work for matching data.\n",
    "    \n",
    "So let's just go through the basic steps from the last article and get the stock index data. Note that I am putting a little bit of code in a python file, you can always get the code (and the notebook used to generate this article) on [github](https://github.com/wrighter/python_blogposts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c8ac375",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "    \n",
    "import pandas as pd\n",
    "\n",
    "from utils import elem2dict, get_nport_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e053be56",
   "metadata": {},
   "outputs": [],
   "source": [
    "website = \"your website\"\n",
    "email = \"your email\"\n",
    "# the N-PORT data for SPY, the S&P 500, 500+ stocks\n",
    "url = \"https://www.sec.gov/Archives/edgar/data/884394/000175272422196968/primary_doc.xml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a718e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nport = get_nport_values(url, website, email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c958933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>lei</th>\n",
       "      <th>title</th>\n",
       "      <th>cusip</th>\n",
       "      <th>identifiers</th>\n",
       "      <th>balance</th>\n",
       "      <th>units</th>\n",
       "      <th>curCd</th>\n",
       "      <th>valUSD</th>\n",
       "      <th>pctVal</th>\n",
       "      <th>payoffProfile</th>\n",
       "      <th>assetCat</th>\n",
       "      <th>issuerCat</th>\n",
       "      <th>invCountry</th>\n",
       "      <th>isRestrictedSec</th>\n",
       "      <th>fairValLevel</th>\n",
       "      <th>securityLending</th>\n",
       "      <th>issuerConditional</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Honeywell International Inc</td>\n",
       "      <td>ISRPG12PN4EIEOEMW547</td>\n",
       "      <td>Honeywell International Inc</td>\n",
       "      <td>438516106</td>\n",
       "      <td>{'isin': {}}</td>\n",
       "      <td>7390330.0</td>\n",
       "      <td>NS</td>\n",
       "      <td>USD</td>\n",
       "      <td>1.284513e+09</td>\n",
       "      <td>0.370781</td>\n",
       "      <td>Long</td>\n",
       "      <td>EC</td>\n",
       "      <td>CORP</td>\n",
       "      <td>US</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>{'isCashCollateral': 'N', 'isNonCashCollateral...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Discover Financial Services</td>\n",
       "      <td>Z1YLO2USPORE63VVUL20</td>\n",
       "      <td>Discover Financial Services</td>\n",
       "      <td>254709108</td>\n",
       "      <td>{'isin': {}}</td>\n",
       "      <td>3050290.0</td>\n",
       "      <td>NS</td>\n",
       "      <td>USD</td>\n",
       "      <td>2.884964e+08</td>\n",
       "      <td>0.083276</td>\n",
       "      <td>Long</td>\n",
       "      <td>EC</td>\n",
       "      <td>CORP</td>\n",
       "      <td>US</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>{'isCashCollateral': 'N', 'isNonCashCollateral...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FMC Corp</td>\n",
       "      <td>CKDHZ2X64EEBQCSP7013</td>\n",
       "      <td>FMC Corp</td>\n",
       "      <td>302491303</td>\n",
       "      <td>{'isin': {}}</td>\n",
       "      <td>1371493.0</td>\n",
       "      <td>NS</td>\n",
       "      <td>USD</td>\n",
       "      <td>1.467635e+08</td>\n",
       "      <td>0.042364</td>\n",
       "      <td>Long</td>\n",
       "      <td>EC</td>\n",
       "      <td>CORP</td>\n",
       "      <td>US</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>{'isCashCollateral': 'N', 'isNonCashCollateral...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nordson Corp</td>\n",
       "      <td>14OS6Q5N55N95WM84M53</td>\n",
       "      <td>Nordson Corp</td>\n",
       "      <td>655663102</td>\n",
       "      <td>{'isin': {}}</td>\n",
       "      <td>587512.0</td>\n",
       "      <td>NS</td>\n",
       "      <td>USD</td>\n",
       "      <td>1.189359e+08</td>\n",
       "      <td>0.034331</td>\n",
       "      <td>Long</td>\n",
       "      <td>EC</td>\n",
       "      <td>CORP</td>\n",
       "      <td>US</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>{'isCashCollateral': 'N', 'isNonCashCollateral...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Charles River Laboratories International Inc</td>\n",
       "      <td>549300BSQ0R4UZ5KX287</td>\n",
       "      <td>Charles River Laboratories International Inc</td>\n",
       "      <td>159864107</td>\n",
       "      <td>{'isin': {}}</td>\n",
       "      <td>541951.0</td>\n",
       "      <td>NS</td>\n",
       "      <td>USD</td>\n",
       "      <td>1.159613e+08</td>\n",
       "      <td>0.033473</td>\n",
       "      <td>Long</td>\n",
       "      <td>EC</td>\n",
       "      <td>CORP</td>\n",
       "      <td>US</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>{'isCashCollateral': 'N', 'isNonCashCollateral...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           name                   lei  \\\n",
       "0                   Honeywell International Inc  ISRPG12PN4EIEOEMW547   \n",
       "1                   Discover Financial Services  Z1YLO2USPORE63VVUL20   \n",
       "2                                      FMC Corp  CKDHZ2X64EEBQCSP7013   \n",
       "3                                  Nordson Corp  14OS6Q5N55N95WM84M53   \n",
       "4  Charles River Laboratories International Inc  549300BSQ0R4UZ5KX287   \n",
       "\n",
       "                                          title      cusip   identifiers  \\\n",
       "0                   Honeywell International Inc  438516106  {'isin': {}}   \n",
       "1                   Discover Financial Services  254709108  {'isin': {}}   \n",
       "2                                      FMC Corp  302491303  {'isin': {}}   \n",
       "3                                  Nordson Corp  655663102  {'isin': {}}   \n",
       "4  Charles River Laboratories International Inc  159864107  {'isin': {}}   \n",
       "\n",
       "     balance units curCd        valUSD    pctVal payoffProfile assetCat  \\\n",
       "0  7390330.0    NS   USD  1.284513e+09  0.370781          Long       EC   \n",
       "1  3050290.0    NS   USD  2.884964e+08  0.083276          Long       EC   \n",
       "2  1371493.0    NS   USD  1.467635e+08  0.042364          Long       EC   \n",
       "3   587512.0    NS   USD  1.189359e+08  0.034331          Long       EC   \n",
       "4   541951.0    NS   USD  1.159613e+08  0.033473          Long       EC   \n",
       "\n",
       "  issuerCat invCountry isRestrictedSec fairValLevel  \\\n",
       "0      CORP         US               N            1   \n",
       "1      CORP         US               N            1   \n",
       "2      CORP         US               N            1   \n",
       "3      CORP         US               N            1   \n",
       "4      CORP         US               N            1   \n",
       "\n",
       "                                     securityLending issuerConditional  \n",
       "0  {'isCashCollateral': 'N', 'isNonCashCollateral...               NaN  \n",
       "1  {'isCashCollateral': 'N', 'isNonCashCollateral...               NaN  \n",
       "2  {'isCashCollateral': 'N', 'isNonCashCollateral...               NaN  \n",
       "3  {'isCashCollateral': 'N', 'isNonCashCollateral...               NaN  \n",
       "4  {'isCashCollateral': 'N', 'isNonCashCollateral...               NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nport.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010ff70a",
   "metadata": {},
   "source": [
    "## A first check\n",
    "Looking at this data, you can see that there is a company name, something called an lei, and a CUSIP. The ISIN is not supplied in this file. The CUSIP and ISIN and LEI are standard financial industry identifiers.\n",
    "\n",
    "We want to turn either the name, LE, or CUSIP into Stock Exchange tickers. (Note that I will use the term symbol interchangeably for ticker). If we have the symbol, we can translate that to a CIK, the internal company code used by the SEC. If you use the [EDGAR search page](https://www.sec.gov/edgar/searchedgar/companysearch), you can enter a symbol, name *or* CIK. But we don't want to manually process all 505 rows of the DataFrame. And even if we did submit the name, there might be multiple matches presented by the user interface. \n",
    "\n",
    "How do we automate the mapping? Ideally, we could just find a free source of CUSIP to ticker cross references. If you work in the financial industry, you would surely have a system at work that does this for you, and this article would be pointless. I wasn't able to find a free and reliable API that does CUSIP to ticker mappings, though maybe one does exist.  Sometimes, you can find free sources for more popular stock indexes (including Wikipedia), but we'd like to have this mapping work for *any* stock, even ones in the more obscure indexes. For the purposes of this article, let's pretend that we have to figure this out with only what we can observe on EDGAR.\n",
    "\n",
    "## A starting point\n",
    "The SEC does publish a cross reference for CIK to symbol, and that mapping also contains a company name.\n",
    "Let's start there. The file is a just a big JSON object, which we can convert to a `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c51f3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cik_str': 320193, 'ticker': 'AAPL', 'title': 'Apple Inc.'}\n",
      "(11975, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cik_str</th>\n",
       "      <th>ticker</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>320193</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>789019</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>MICROSOFT CORP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1018724</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>AMAZON COM INC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1067983</td>\n",
       "      <td>BRK-B</td>\n",
       "      <td>BERKSHIRE HATHAWAY INC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>731766</td>\n",
       "      <td>UNH</td>\n",
       "      <td>UNITEDHEALTH GROUP INC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>34088</td>\n",
       "      <td>XOM</td>\n",
       "      <td>EXXON MOBIL CORP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>200406</td>\n",
       "      <td>JNJ</td>\n",
       "      <td>JOHNSON &amp; JOHNSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>104169</td>\n",
       "      <td>WMT</td>\n",
       "      <td>Walmart Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>19617</td>\n",
       "      <td>JPM</td>\n",
       "      <td>JPMORGAN CHASE &amp; CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>93410</td>\n",
       "      <td>CVX</td>\n",
       "      <td>CHEVRON CORP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cik_str ticker                   title\n",
       "0   320193   AAPL              Apple Inc.\n",
       "1   789019   MSFT          MICROSOFT CORP\n",
       "2  1018724   AMZN          AMAZON COM INC\n",
       "3  1067983  BRK-B  BERKSHIRE HATHAWAY INC\n",
       "4   731766    UNH  UNITEDHEALTH GROUP INC\n",
       "5    34088    XOM        EXXON MOBIL CORP\n",
       "6   200406    JNJ       JOHNSON & JOHNSON\n",
       "7   104169    WMT            Walmart Inc.\n",
       "8    19617    JPM     JPMORGAN CHASE & CO\n",
       "9    93410    CVX            CHEVRON CORP"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbol_to_cik = requests.get(\"https://www.sec.gov/files/company_tickers.json\").json()\n",
    "print(symbol_to_cik['0'])\n",
    "\n",
    "symbol_to_cik = pd.DataFrame(symbol_to_cik).T\n",
    "print(symbol_to_cik.shape)\n",
    "symbol_to_cik.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c439c4",
   "metadata": {},
   "source": [
    "As you can see, it has a lot of symbols, over 11K. Looking at the list, I suspect that it is probably sorted by search frequency on EDGAR or popularity. We see that Apple Inc. is the most popular and has a ticker of `AAPL` and a CIK of `320193`.\n",
    "\n",
    "Let's look at the largest holdings in the S&P 500. If you recall from the previous article, the S&P 500 is a market cap weighted index, so it contains more of the larger companies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8a20191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>cusip</th>\n",
       "      <th>pctVal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>Apple Inc</td>\n",
       "      <td>037833100</td>\n",
       "      <td>6.587783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>Microsoft Corp</td>\n",
       "      <td>594918104</td>\n",
       "      <td>6.019457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>Amazon.com Inc</td>\n",
       "      <td>023135106</td>\n",
       "      <td>2.912308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>Alphabet Inc</td>\n",
       "      <td>02079K305</td>\n",
       "      <td>2.054029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>Alphabet Inc</td>\n",
       "      <td>02079K107</td>\n",
       "      <td>1.890388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>Tesla Inc</td>\n",
       "      <td>88160R101</td>\n",
       "      <td>1.770921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>Berkshire Hathaway Inc</td>\n",
       "      <td>084670702</td>\n",
       "      <td>1.547893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>UnitedHealth Group Inc</td>\n",
       "      <td>91324P102</td>\n",
       "      <td>1.511444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Johnson &amp; Johnson</td>\n",
       "      <td>478160104</td>\n",
       "      <td>1.463783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>NVIDIA Corp</td>\n",
       "      <td>67066G104</td>\n",
       "      <td>1.189526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>Meta Platforms Inc</td>\n",
       "      <td>30303M102</td>\n",
       "      <td>1.158956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>Exxon Mobil Corp</td>\n",
       "      <td>30231G102</td>\n",
       "      <td>1.130543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>Procter &amp; Gamble Co/The</td>\n",
       "      <td>742718109</td>\n",
       "      <td>1.081133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>JPMorgan Chase &amp; Co</td>\n",
       "      <td>46625H100</td>\n",
       "      <td>1.036458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>Visa Inc</td>\n",
       "      <td>92826C839</td>\n",
       "      <td>1.015419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       title      cusip    pctVal\n",
       "433                Apple Inc  037833100  6.587783\n",
       "186           Microsoft Corp  594918104  6.019457\n",
       "483           Amazon.com Inc  023135106  2.912308\n",
       "140             Alphabet Inc  02079K305  2.054029\n",
       "223             Alphabet Inc  02079K107  1.890388\n",
       "290                Tesla Inc  88160R101  1.770921\n",
       "268   Berkshire Hathaway Inc  084670702  1.547893\n",
       "49    UnitedHealth Group Inc  91324P102  1.511444\n",
       "44         Johnson & Johnson  478160104  1.463783\n",
       "214              NVIDIA Corp  67066G104  1.189526\n",
       "344       Meta Platforms Inc  30303M102  1.158956\n",
       "250         Exxon Mobil Corp  30231G102  1.130543\n",
       "170  Procter & Gamble Co/The  742718109  1.081133\n",
       "481      JPMorgan Chase & Co  46625H100  1.036458\n",
       "148                 Visa Inc  92826C839  1.015419"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nport.sort_values(by='pctVal', ascending=False).head(15)[['title', 'cusip', 'pctVal']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab53d29",
   "metadata": {},
   "source": [
    "Our job is to find the ticker by searching for the title/name that matches. Could this work? By inspection, I spot a few issues:\n",
    "* the CIK lookup has `Apple Inc.` whereas the N-PORT contains `Apple Inc` (without the period)\n",
    "* Microsoft is capitalized in one and not the other\n",
    "* Companies that start with `The` have it placed at the end in N-PORT\n",
    "* There are duplicate rows for Alphabet Inc\n",
    "\n",
    "So it's not going to be too straightforward, but let's give it a quick try. Our initial approach is to do a pandas merge, joining on the title exactly, and doing a left join. This means we want *all* rows from the left DataFrame, and will get null values for the new merged columns if there's not a match. We'll create a new DataFrame to hold these results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3acbb77a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 20)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nport_tickers = nport.merge(symbol_to_cik, left_on='title', right_on='title', how='left')\n",
    "nport_tickers.loc[~pd.isnull(nport_tickers['ticker'])].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfb7f1f",
   "metadata": {},
   "source": [
    "OK, we got 52 exact matches out of 505 rows. That's a start, but not very good. What do the matches (non-null rows) look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc58891a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Discover Financial Services</td>\n",
       "      <td>DFS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>General Motors Co</td>\n",
       "      <td>GM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Viatris Inc</td>\n",
       "      <td>VTRS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Marathon Petroleum Corp</td>\n",
       "      <td>MPC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Snap-on Inc</td>\n",
       "      <td>SNA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Chubb Ltd</td>\n",
       "      <td>CB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Allegion plc</td>\n",
       "      <td>ALLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>Celanese Corp</td>\n",
       "      <td>CE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Fox Corp</td>\n",
       "      <td>FOXA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>Fox Corp</td>\n",
       "      <td>FOX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>PPL Corp</td>\n",
       "      <td>PPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>Phillips 66</td>\n",
       "      <td>PSX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>Hewlett Packard Enterprise Co</td>\n",
       "      <td>HPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>Archer-Daniels-Midland Co</td>\n",
       "      <td>ADM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>Baker Hughes Co</td>\n",
       "      <td>BKR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>Vontier Corp</td>\n",
       "      <td>VNT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>Paramount Global</td>\n",
       "      <td>PARA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>Paramount Global</td>\n",
       "      <td>PARAA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>Paramount Global</td>\n",
       "      <td>PARAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>Constellation Energy Corp</td>\n",
       "      <td>CEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>Johnson Controls International plc</td>\n",
       "      <td>JCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>Cigna Corp</td>\n",
       "      <td>CI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>Public Storage</td>\n",
       "      <td>PSA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>Public Storage</td>\n",
       "      <td>PSA-PH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>Public Storage</td>\n",
       "      <td>PSA-PK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>Public Storage</td>\n",
       "      <td>PSA-PL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>Public Storage</td>\n",
       "      <td>PSA-PF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>Public Storage</td>\n",
       "      <td>PSA-PQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>Public Storage</td>\n",
       "      <td>PSA-PJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>Public Storage</td>\n",
       "      <td>PSA-PG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>Public Storage</td>\n",
       "      <td>PSA-PO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>Public Storage</td>\n",
       "      <td>PSA-PS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>Public Storage</td>\n",
       "      <td>PSA-PR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>Public Storage</td>\n",
       "      <td>PSA-PN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>Public Storage</td>\n",
       "      <td>PSA-PI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>Public Storage</td>\n",
       "      <td>PSA-PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>Public Storage</td>\n",
       "      <td>PSA-PP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>Monster Beverage Corp</td>\n",
       "      <td>MNST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>Mastercard Inc</td>\n",
       "      <td>MA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>DXC Technology Co</td>\n",
       "      <td>DXC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>Synchrony Financial</td>\n",
       "      <td>SYF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>Synchrony Financial</td>\n",
       "      <td>SYF-PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>APA Corp</td>\n",
       "      <td>APA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>MGM Resorts International</td>\n",
       "      <td>MGM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>Edwards Lifesciences Corp</td>\n",
       "      <td>EW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>Avery Dennison Corp</td>\n",
       "      <td>AVY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>Fox Corp</td>\n",
       "      <td>FOXA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>Fox Corp</td>\n",
       "      <td>FOX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>Otis Worldwide Corp</td>\n",
       "      <td>OTIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>Fortive Corp</td>\n",
       "      <td>FTV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>Aptiv PLC</td>\n",
       "      <td>APTV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>Aptiv PLC</td>\n",
       "      <td>APTV-PA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  title   ticker\n",
       "1           Discover Financial Services      DFS\n",
       "25                    General Motors Co       GM\n",
       "35                          Viatris Inc     VTRS\n",
       "61              Marathon Petroleum Corp      MPC\n",
       "96                          Snap-on Inc      SNA\n",
       "100                           Chubb Ltd       CB\n",
       "110                        Allegion plc     ALLE\n",
       "113                       Celanese Corp       CE\n",
       "119                            Fox Corp     FOXA\n",
       "120                            Fox Corp      FOX\n",
       "121                            PPL Corp      PPL\n",
       "145                         Phillips 66      PSX\n",
       "150       Hewlett Packard Enterprise Co      HPE\n",
       "157           Archer-Daniels-Midland Co      ADM\n",
       "161                     Baker Hughes Co      BKR\n",
       "164                        Vontier Corp      VNT\n",
       "190                    Paramount Global     PARA\n",
       "191                    Paramount Global    PARAA\n",
       "192                    Paramount Global    PARAP\n",
       "204           Constellation Energy Corp      CEG\n",
       "220  Johnson Controls International plc      JCI\n",
       "228                          Cigna Corp       CI\n",
       "250                      Public Storage      PSA\n",
       "251                      Public Storage   PSA-PH\n",
       "252                      Public Storage   PSA-PK\n",
       "253                      Public Storage   PSA-PL\n",
       "254                      Public Storage   PSA-PF\n",
       "255                      Public Storage   PSA-PQ\n",
       "256                      Public Storage   PSA-PJ\n",
       "257                      Public Storage   PSA-PG\n",
       "258                      Public Storage   PSA-PO\n",
       "259                      Public Storage   PSA-PS\n",
       "260                      Public Storage   PSA-PR\n",
       "261                      Public Storage   PSA-PN\n",
       "262                      Public Storage   PSA-PI\n",
       "263                      Public Storage   PSA-PM\n",
       "264                      Public Storage   PSA-PP\n",
       "283               Monster Beverage Corp     MNST\n",
       "295                      Mastercard Inc       MA\n",
       "302                   DXC Technology Co      DXC\n",
       "325                 Synchrony Financial      SYF\n",
       "326                 Synchrony Financial   SYF-PA\n",
       "351                            APA Corp      APA\n",
       "357           MGM Resorts International      MGM\n",
       "374           Edwards Lifesciences Corp       EW\n",
       "376                 Avery Dennison Corp      AVY\n",
       "381                            Fox Corp     FOXA\n",
       "382                            Fox Corp      FOX\n",
       "431                 Otis Worldwide Corp     OTIS\n",
       "449                        Fortive Corp      FTV\n",
       "481                           Aptiv PLC     APTV\n",
       "482                           Aptiv PLC  APTV-PA"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nport_tickers.loc[~pd.isnull(nport_tickers['ticker']), ['title', 'ticker']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a707e9",
   "metadata": {},
   "source": [
    "## Assessing the exact matches\n",
    "I see several issues. First, some of the symbols show up more than once (`FOXA`, `FOX`), and some of the titles show up multiple times (`Fox Corp`, `Public Storage`, `Synchrony Financial`, `Paramount Global`). Why does this happen? \n",
    "\n",
    "Well, in some cases, companies might have more than one publicly traded common stock listing. If that's the case, and they are in the S&P 500, then they will have *both* stocks in the index. In other cases, companies may have other shares listed that are preferred shares. In still other cases, the companies may have different classes of shares, and only one class of shares are part of the index.\n",
    "\n",
    "So we will need a better solution than a simple match on title. We will need to consider two issues:\n",
    "\n",
    "1. The fact that the title doesn't match exactly\n",
    "1. The fact that matching companies may have more than one matching symbol\n",
    "\n",
    "We also have a bit of extra info in that the symbol to CIK mapping appears to be sorted by search popularity or market cap, so we use this information to weight the first match more heavily if we find multiple matches.\n",
    "\n",
    "We'll build a simple matching algorithm to solve this.\n",
    "\n",
    "## A first attempt at improving matching on title\n",
    "Since this data is somewhat messy, let's see if we can get better than 10% of the names to match. Consider two of the names we looked at above, Apple and Microsoft. For Microsoft, we could force the title to all upper or all lower case and get a match. For Apple, we could remove puncuation. It also makes sense to remove some common words found in many of the company names, especially the trailing `/The`. We can do this using regular expressions with `replace` on string columns.\n",
    "\n",
    "Now, regular expressions can be a confusing topic. Don't look at this one and think I did this in one step. Instead, here's the approach I used. First, I looked at the top 50 values in the `DataFrame`.\n",
    "```python\n",
    "symbol_to_cik[\"title\"]\n",
    "```\n",
    "\n",
    "Then, I started to chain methods the pandas string methods, starting with converting all the strings to upper case, and adding regular expressions to replacing words one at a time, re-executing the cell with the code until it gave me the final result.\n",
    "\n",
    "Even after doing that, I found that it needed tweaking a few times after I continued through the process in this article. This is what I ended up with, with a full explanation of the regex (note you can't run the code with these comments inline, you need to run what is in the cells below. To follow along at home, you can just try these lines one at a time to see what changes).\n",
    "\n",
    "```python\n",
    "symbol_to_cik[\"title\"].str                 # use the pandas string methods\n",
    "    .upper()                               # convert to upper case so words match\n",
    "    .replace(r\"\\.|\\,|&\", \" \", regex=True)  # replace punctuation with space, (,.&)\n",
    "    .replace(r\"\\/(\\w+)?(\\/)?\", \" \", regex=True)  # replace words like this /xx/ with a space\n",
    "    .replace(r\"\\s(CO[M|S|R]?P?|INC|PLC|LP|NA|NV|CU|LTD)(?=\\s|$)\", \"\", regex=True)  # remove common words\n",
    "    .replace(r\"\\s+\", \" \", regex=True).str.strip() # remove all extra spaces\n",
    "\n",
    "```\n",
    "\n",
    "Let's also break this line down a bit more. This expression might be a bit confusing:\n",
    "```python\n",
    "r\"\\s(CO[M|S|R]?P?|INC|PLC|LP|NA|NV|CU|LTD)(?=\\s|$)\"\n",
    "```\n",
    "\n",
    "This is saying match a space, followed by the word COM or COS or COR or CORP or INC or PLC or LP or NA or NV or CU or LTD followed by a space or the end of the line. The `?=` is a lookhead, so it's checking that the space or end of line exists in order to match, but it doesn't consume it in the replacement. This allows us to replace multiple matching words in a row, like in `Amazon.com Inc` (which becomes `AMAZON COM INC`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e49a85b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FOO   '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "re.sub(\"\\s(CO[M|S|R]?P?|INC|PLC|LP|NA|NV|CU|LTD)(?=\\s|$)\", \" \", \"FOO LTD PLC CORP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4674df3",
   "metadata": {},
   "source": [
    "## Applying the title changes\n",
    "Now we'll apply the title search changes. Note how the names now just contain the \"main\" part of their name, not all the extra adornments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02183c4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                  APPLE\n",
       "1                              MICROSOFT\n",
       "2                                 AMAZON\n",
       "3                     BERKSHIRE HATHAWAY\n",
       "4                     UNITEDHEALTH GROUP\n",
       "5                            EXXON MOBIL\n",
       "6                        JOHNSON JOHNSON\n",
       "7                                WALMART\n",
       "8                         JPMORGAN CHASE\n",
       "9                                CHEVRON\n",
       "10                             ELI LILLY\n",
       "11                SPDR S P 500 ETF TRUST\n",
       "12                                NVIDIA\n",
       "13                        PROCTER GAMBLE\n",
       "14    TAIWAN SEMICONDUCTOR MANUFACTURING\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_title_search(df):\n",
    "    return df[\"title\"].str.upper() \\\n",
    "        .replace(r\"\\.|\\,|&\", \" \", regex=True) \\\n",
    "        .replace(r\"\\/(\\w+)?(\\/)?\", \" \", regex=True) \\\n",
    "        .replace(r\"\\s(CO[M|S|R]?P?|INC|PLC|LP|NA|NV|CU|LTD)(?=\\s|$)\", \"\", regex=True) \\\n",
    "        .replace(r\"\\s+\", \" \", regex=True).str.strip()\n",
    "\n",
    "make_title_search(symbol_to_cik).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e496b0a",
   "metadata": {},
   "source": [
    "We will make a new column for merging, then do a new merge using that column on both `DataFrames`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6de72a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(629, 22)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbol_to_cik[\"title-search\"] = make_title_search(symbol_to_cik)\n",
    "nport[\"title-search\"] = make_title_search(nport)\n",
    "\n",
    "nport_tickers = nport.merge(symbol_to_cik, left_on='title-search', right_on='title-search', how='left')\n",
    "nport_tickers.loc[~pd.isnull(nport_tickers['ticker'])].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191a7982",
   "metadata": {},
   "source": [
    "## Analyzing the new match results\n",
    "Whoa, we now have more matches than we had original rows! Let's look at cases where we have multiple matches. One quick way to do this is to group by the matching criteria (the `title-search` column in our case), and count the values. The result is the number of rows found for that match. We pick a random column (`cusip`) to make the output more readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e7999fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title-search\n",
       "BANK OF AMERICA          17\n",
       "PUBLIC STORAGE           15\n",
       "MORGAN STANLEY            9\n",
       "FIRST REPUBLIC BANK       8\n",
       "JPMORGAN CHASE            8\n",
       "CAPITAL ONE FINANCIAL     6\n",
       "VORNADO REALTY TRUST      6\n",
       "GOLDMAN SACHS GROUP       6\n",
       "KEYCORP                   5\n",
       "ALLSTATE                  5\n",
       "Name: cusip, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nport_tickers.groupby(\"title-search\").count().sort_values(by=\"cusip\", ascending=False).head(10)['cusip']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a76afb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "362       BAC\n",
       "363    BML-PG\n",
       "364    BML-PH\n",
       "365    BAC-PB\n",
       "366    BAC-PK\n",
       "367    BML-PL\n",
       "368    BAC-PL\n",
       "369    BAC-PE\n",
       "370    BML-PJ\n",
       "371    BAC-PM\n",
       "372    BAC-PN\n",
       "373    BAC-PP\n",
       "374    BAC-PQ\n",
       "375    BAC-PO\n",
       "376     BACRP\n",
       "377    MER-PK\n",
       "378    BAC-PS\n",
       "Name: ticker, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nport_tickers.loc[nport_tickers[\"title-search\"] == 'BANK OF AMERICA', \"ticker\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92dfda1e",
   "metadata": {},
   "source": [
    "This is similar to what we saw earlier with some companies having mutiple matches for preferred stock listings. We can see that the first match is _probably_ the best one, so we need to further enhance our matching algorithm. We benefit from the fact that our `symbol_to_cik` `DataFrame` is sorted in order of popularity. It's very likely that the first match we encounter is the symbol we want.\n",
    "\n",
    "## A second attempt at improving matching with duplicates\n",
    "Since our simple merge results in duplicate rows, we can clean up our data by only keeping the *best* row, or in our case the first one. There are a few approaches you can use when you want to remove duplicate data in pandas. You can read [this article](https://www.wrighters.io/removing-duplicate-data-in-pandas/) for some more detail of to remove duplicates and keep certain data. In our case, we are grouping by `title-search`, but since the data is sorted by \"most popular\", we can choose the first match. So an approach using `groupby`, with `first()` works well.  This will group by our search title, and pick the first match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18de7d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    name      cusip ticker\n",
      "title-search                                              \n",
      "3M                                 3M Co  88579Y101    MMM\n",
      "A O SMITH                 A O Smith Corp  831865209   None\n",
      "ABBOTT LABORATORIES  Abbott Laboratories  002824100    ABT\n",
      "ABBVIE                        AbbVie Inc  00287Y109   ABBV\n",
      "ABIOMED                      ABIOMED Inc  003654100   ABMD\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(502, 21)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nport_second_attempt = nport_tickers.groupby(\"title-search\").first()\n",
    "print(nport_second_attempt.head()[['name', 'cusip', 'ticker']])\n",
    "nport_second_attempt.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcaefb42",
   "metadata": {},
   "source": [
    "Looking at the results, we see several problems. The first problem here is that this results in removing 3 rows. You'll recall our original `nport` `DataFrame` had 505 rows. Three of the companies have the same exact `title-search`, so we are only picking one of them when we do the `groupby`. The second issue we see above is not all tickers were matched. Let's look at how many missing symbols we have at this stage, and see what some of these look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46631044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 21)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nport_second_attempt.loc[pd.isnull(nport_second_attempt[\"ticker\"])].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ed8dddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title-search\n",
       "A O SMITH                                     A O Smith Corp\n",
       "AIR PRODUCTS AND CHEMICALS    Air Products and Chemicals Inc\n",
       "AMERICAN WATER WORKS             American Water Works Co Inc\n",
       "BECTON DICKINSON AND                 Becton Dickinson and Co\n",
       "BRISTOL-MYERS SQUIBB                 Bristol-Myers Squibb Co\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nport_second_attempt.loc[pd.isnull(nport_second_attempt[\"ticker\"])].head()['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cab091e",
   "metadata": {},
   "source": [
    "So at this point, we can match roughly 90% of our symbols, and we have an issue with three of our companies having two choices. We need a slightly better matching method. Let's see how we might match the missing values, starting with _A O Smith Corp_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89be016f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cik_str</th>\n",
       "      <th>ticker</th>\n",
       "      <th>title</th>\n",
       "      <th>title-search</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>845982</td>\n",
       "      <td>SNN</td>\n",
       "      <td>SMITH &amp; NEPHEW PLC</td>\n",
       "      <td>SMITH NEPHEW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>91142</td>\n",
       "      <td>AOS</td>\n",
       "      <td>SMITH A O CORP</td>\n",
       "      <td>SMITH A O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1752</th>\n",
       "      <td>1689796</td>\n",
       "      <td>JBGS</td>\n",
       "      <td>JBG SMITH Properties</td>\n",
       "      <td>JBG SMITH PROPERTIES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3210</th>\n",
       "      <td>1092796</td>\n",
       "      <td>SWBI</td>\n",
       "      <td>SMITH &amp; WESSON BRANDS, INC.</td>\n",
       "      <td>SMITH WESSON BRANDS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4952</th>\n",
       "      <td>948708</td>\n",
       "      <td>SMSI</td>\n",
       "      <td>SMITH MICRO SOFTWARE, INC.</td>\n",
       "      <td>SMITH MICRO SOFTWARE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4990</th>\n",
       "      <td>924719</td>\n",
       "      <td>SMID</td>\n",
       "      <td>SMITH MIDLAND CORP</td>\n",
       "      <td>SMITH MIDLAND</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cik_str ticker                        title          title-search\n",
       "748    845982    SNN           SMITH & NEPHEW PLC          SMITH NEPHEW\n",
       "864     91142    AOS               SMITH A O CORP             SMITH A O\n",
       "1752  1689796   JBGS         JBG SMITH Properties  JBG SMITH PROPERTIES\n",
       "3210  1092796   SWBI  SMITH & WESSON BRANDS, INC.   SMITH WESSON BRANDS\n",
       "4952   948708   SMSI   SMITH MICRO SOFTWARE, INC.  SMITH MICRO SOFTWARE\n",
       "4990   924719   SMID           SMITH MIDLAND CORP         SMITH MIDLAND"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbol_to_cik[symbol_to_cik[\"title\"].str.contains(\"SMITH\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431f7587",
   "metadata": {},
   "source": [
    "## Fuzzy matching\n",
    "We need to find a way to match the *closest* name. For this first example, consider how we are searching for `A O SMITH` but that doesn't match the correct value, `SMITH A O`, with ticker [AOS](https://en.wikipedia.org/wiki/A._O._Smith). We need a solution that would look through all the titles and find the closest match.\n",
    "\n",
    "There is a metric in linguistics and computer science known as the [Levenshtein distance](https://en.wikipedia.org/wiki/Levenshtein_distance). It gives a good approximation the similarity of two strings. We don't have to implement this algorithm on our own (though you can do that!), there's an existing Python library that makes it easy to do fuzzy searches. It's called [the fuzz](https://github.com/seatgeek/thefuzz) (formerly known as fuzzy wuzzy). \n",
    "\n",
    "You can install it using \n",
    "\n",
    "```\n",
    "pip install \"thefuzz[speedup]\"\n",
    "```\n",
    "\n",
    "or just\n",
    "```\n",
    "pip install thefuzz\n",
    "```\n",
    "\n",
    "The former will install a faster implementation of the Levenshtein distance calculation.\n",
    "\n",
    "You can read the documentation for more examples, but here's a quick look using our example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7dc2274c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from thefuzz import fuzz, process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f55adb64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95\n",
      "95\n",
      "18\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "print(fuzz.WRatio(\"A O SMITH\", \"SMITH A O\"))\n",
    "print(fuzz.WRatio(\"A O SMITH\", \"A. O. Smith\"))\n",
    "print(fuzz.WRatio(\"A O SMITH\", \"Apple\"))\n",
    "print(fuzz.WRatio(\"A O SMITH\", \"A O SMITH\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ef35ec",
   "metadata": {},
   "source": [
    "We then use the `process.extract` function to search through a list of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf6a4893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('SMITH A O', 95, '864'),\n",
       " ('NOVO NORDISK A S', 86, '20'),\n",
       " ('ITAU UNIBANCO HOLDING S A', 86, '176'),\n",
       " ('O REILLY AUTOMOTIVE', 86, '189'),\n",
       " ('PERNOD RICARD S A', 86, '230')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process.extract(\"A O SMITH\", symbol_to_cik[\"title-search\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a85a80",
   "metadata": {},
   "source": [
    "The results returned by `process` are the matched value (`SMITH A O`), along with the score (`95`) and the index (`'872'`) of the matched value. We can use the index to find the row in the lookup `DataFrame` and get the symbol and CIK from it. You also notice that the similarity score can actually be pretty high even when the two values don't look very similar. We need to ensure that we don't use the wrong value if the match isn't good enough. We'll add a threshold to our search.\n",
    "\n",
    "Since it's possible for a single company to have multiple matches, we also want to make sure we only use a value once. We do track our choices and ensure we don't reuse them. We'll end up picking the two most popular symbols for those companies with multiple matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f19798d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_title(title, used, lookup, threshold=90):\n",
    "    # get all the matches\n",
    "    results = process.extract(title, lookup[\"title-search\"])\n",
    "    for res in results:\n",
    "        if res[1] < threshold:\n",
    "            return\n",
    "        idx = res[2]\n",
    "        if idx not in used:\n",
    "            # return first non-used result\n",
    "            used.add(idx)\n",
    "            row = lookup.loc[idx]\n",
    "            return row['cik_str'], row['ticker'], res[0], res[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2660562e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320193, 'AAPL', 'APPLE', 100)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "used = set()\n",
    "find_title(\"APPLE\", used, symbol_to_cik)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcd98ad",
   "metadata": {},
   "source": [
    "OK, fair enough. But how does it handle the symbols that were problems? Let's see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e178da3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1754301, 'FOXA', 'FOX', 100)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_title(\"FOX\", used, symbol_to_cik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "117b0498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1754301, 'FOX', 'FOX', 100)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_title(\"FOX\", used, symbol_to_cik)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0ad3e7",
   "metadata": {},
   "source": [
    "OK, that seems to potentially work. We see that they both have the *same* CIK, but we get two stock symbols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f775aea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(813828, 'PARA', 'PARAMOUNT GLOBAL', 100)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_title(\"PARAMOUNT GLOBAL\", used, symbol_to_cik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8ea622ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1393311, 'PSA', 'PUBLIC STORAGE', 100)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_title(\"PUBLIC STORAGE\", used, symbol_to_cik)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eadfdd4",
   "metadata": {},
   "source": [
    "Let's make sure a fake company doesn't work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bcd573cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_title(\"Vandalay Industries\", set(), symbol_to_cik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "97060b9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1489393, 'LYB', 'LYONDELLBASELL INDUSTRIES N V', 86)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_title(\"Vandalay Industries\", set(), symbol_to_cik, threshold=50) # very low threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ae3643",
   "metadata": {},
   "source": [
    "This seems to be working. If multiple rows in the lookup match the name, it's picking the first match which happens to be the most popular due to the sorting of `symbol_to_cik`. If we wanted to choose a better algorithm for selecting the match, we could easily do that.\n",
    "\n",
    "Now before we try to run this on the full dataset, let's see what we're in for. (Note when creating this article, I tried running the whole dataset first and saw that it was incredibly slow, as I was expecting). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b8a3f057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "614 ms  4.15 ms per loop (mean  std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit find_title(\"Public Storage\", set(), symbol_to_cik)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1e4566",
   "metadata": {},
   "source": [
    "Running one title takes a bit less than a second. So we'd expect the full 505 symbols to take 5-7 minutes. While that's not a crazy amount of time, this is not something we'd want to run multiple times or on a larger data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "230c68a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "used.clear() # we want to restart\n",
    "cik_symbol = nport[\"title-search\"].apply(lambda t: find_title(t, used, symbol_to_cik))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6efefa",
   "metadata": {},
   "source": [
    "Note that cik_symbol is a `Series` with the same index as nport, with two values. Let's put them into our `DataFrame`. The reason this is slow is that each title is passed into the `find_title` function, and that function has to run the fuzzy search over every name in the set for each row.\n",
    "\n",
    "Let's first check if any of the returned values were not set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "87b784bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          (773840, HON, HONEYWELL INTERNATIONAL, 100)\n",
      "1     (1393612, DFS, DISCOVER FINANCIAL SERVICES, 100)\n",
      "2                               (37785, FMC, FMC, 100)\n",
      "3                          (72331, NDSN, NORDSON, 100)\n",
      "4    (1100682, CRL, CHARLES RIVER LABORATORIES INTE...\n",
      "Name: title-search, dtype: object\n",
      "There are  6 missing values\n"
     ]
    }
   ],
   "source": [
    "print(cik_symbol.head())\n",
    "print(\"There are \", cik_symbol[pd.isnull(cik_symbol)].shape[0], \"missing values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ea1db0",
   "metadata": {},
   "source": [
    "This is pretty good, only 6 of our values didn't find a match. We don't know yet if the matches are correct, but matching almost 500 names with a fuzzy score of 90+ is a good start.\n",
    "\n",
    "Since both `nport` and `cik_symbol` have the same index, we can just update the data directly. Since there were null rows above, we need to handle null in our update. There is a tuple of 4 values in each row on the `Series` so we need to `apply` a `lambda` to the data, returning the first (CIK) and second (symbol) values appropriately. I use a little trick here with the `lambda`. If the row (passed into the lambda as `x`) is *not* `None`, then return the correct value, othewise, just return `x` (which is `None`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4eeb835e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nport['cik'] = cik_symbol.apply(lambda x: x and x[0] or x)\n",
    "nport['symbol'] = cik_symbol[~pd.isnull(cik_symbol)].apply(lambda x: x and x[1] or x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf579dca",
   "metadata": {},
   "source": [
    "Now let's look at our missing values to see if we can figure out why we didn't get a match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "536cdfd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>title-search</th>\n",
       "      <th>cusip</th>\n",
       "      <th>symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>Lowe's Cos Inc</td>\n",
       "      <td>LOWE'S</td>\n",
       "      <td>548661107</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>Federal Realty OP LP</td>\n",
       "      <td>FEDERAL REALTY OP</td>\n",
       "      <td>313745101</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>Sherwin-Williams Co/The</td>\n",
       "      <td>SHERWIN-WILLIAMS</td>\n",
       "      <td>824348106</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>Jacobs Engineering Group Inc</td>\n",
       "      <td>JACOBS ENGINEERING GROUP</td>\n",
       "      <td>469814107</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>JB Hunt Transport Services Inc</td>\n",
       "      <td>JB HUNT TRANSPORT SERVICES</td>\n",
       "      <td>445658107</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>Nielsen Holdings PLC</td>\n",
       "      <td>NIELSEN HOLDINGS</td>\n",
       "      <td>000000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              title                title-search      cusip  \\\n",
       "175                  Lowe's Cos Inc                      LOWE'S  548661107   \n",
       "203            Federal Realty OP LP           FEDERAL REALTY OP  313745101   \n",
       "327         Sherwin-Williams Co/The            SHERWIN-WILLIAMS  824348106   \n",
       "365    Jacobs Engineering Group Inc    JACOBS ENGINEERING GROUP  469814107   \n",
       "383  JB Hunt Transport Services Inc  JB HUNT TRANSPORT SERVICES  445658107   \n",
       "388            Nielsen Holdings PLC            NIELSEN HOLDINGS  000000000   \n",
       "\n",
       "    symbol  \n",
       "175    NaN  \n",
       "203    NaN  \n",
       "327    NaN  \n",
       "365    NaN  \n",
       "383    NaN  \n",
       "388    NaN  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nport.loc[pd.isnull(nport['symbol']), ['title', 'title-search', 'cusip', 'symbol']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a0dee7",
   "metadata": {},
   "source": [
    "First, we will try Lowe's without the apostrophe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "681b813d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60667, 'LOW', 'LOWES COMPANIES', 90)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_title(\"LOWES\", set(), symbol_to_cik, threshold=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cddca4",
   "metadata": {},
   "source": [
    "If we add a `'` to our replacement regex earlier, this issue would be taken care of. Now what about `Federal Realty OP`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2e5dd0b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34903, 'FRT', 'FEDERAL REALTY INVESTMENT TRUST', 86)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_title(\"FEDERAL REALTY OP\", set(), symbol_to_cik, threshold=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "db74a817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34903, 'FRT', 'FEDERAL REALTY INVESTMENT TRUST', 90)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_title(\"FEDERAL REALTY\", set(), symbol_to_cik, threshold=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206dbe18",
   "metadata": {},
   "source": [
    "So we can see that if add `OP` to our replacement words earlier, we'd find a match. What about the rest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6f16963f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89800, 'SHW', 'SHERWIN WILLIAMS', 100)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_title(\"SHERWIN-WILLIAMS\", set(), symbol_to_cik, threshold=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1807c64a",
   "metadata": {},
   "source": [
    "It look like for Sherwin-Williams, the symbol was \"stolen\" by another company. Who has the value for `SHW`? That will need to be corrected. We can do another search for the result and swap their tickers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f3409dba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95    Williams Cos Inc/The\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nport.loc[nport['symbol'] == 'SHW', 'title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9a65ca5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(107263, 'WMB', 'WILLIAMS COMPANIES', 90)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pass in our previously used values so it doesn't pick 'Sherwin-Williams' again. What's the second choice?\n",
    "find_title(\"Williams\", used, symbol_to_cik, threshold=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f9b40061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52988, 'J', 'JACOBS SOLUTIONS', 90)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_title(\"JACOBS\", set(), symbol_to_cik, threshold=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792227ac",
   "metadata": {},
   "source": [
    "Jacobs has a fairly different name, and is right on the threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dced4fb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(728535, 'JBHT', 'HUNT J B TRANSPORT SERVICES', 89)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_title(\"JB HUNT TRANSPORT SERVICES\", set(), symbol_to_cik, threshold=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f282de",
   "metadata": {},
   "source": [
    "JB Hunt is just below the threshold due to the initials being after the name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e7e57b91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1585689, 'HLT', 'HILTON WORLDWIDE HOLDINGS', 86)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_title(\"NIELSEN HOLDINGS\", set(), symbol_to_cik, threshold=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1a256c",
   "metadata": {},
   "source": [
    "In 2022, [Nielsen Holdings](https://en.wikipedia.org/wiki/Nielsen_Holdings) was taken private. It showed up in an earlier report, but is not active and thus can't be mapped. Let's just fix these all manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "08003557",
   "metadata": {},
   "outputs": [],
   "source": [
    "nport.loc[pd.isnull(nport['symbol']), 'symbol'] = ('LOW', 'FRT', 'SWH', 'J', 'JBHT','NLSN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "834eecf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nport.loc[95, 'symbol'] = 'WMB' # fix the \"stolen\" symbol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efdb4f9",
   "metadata": {},
   "source": [
    "## How did we do?\n",
    "Phew. If you stayed with me through this entire process, congratulations. That was a lot of work. At this point, we have a `DataFrame` that has 503 cusip and symbol entries. How did we do? \n",
    "\n",
    "As I said earlier, getting this mapping can be hard to find for free, but we can grab the current symbol list of S&P 500 companies from different sources, and see how much we overlap to get a rough idea of how we did. Pandas makes grabbing a table from Wikipedia pretty easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2a530698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       MMM\n",
       "1       AOS\n",
       "2       ABT\n",
       "3      ABBV\n",
       "4      ABMD\n",
       "       ... \n",
       "498     YUM\n",
       "499    ZBRA\n",
       "500     ZBH\n",
       "501    ZION\n",
       "502     ZTS\n",
       "Name: Symbol, Length: 503, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp500 = pd.read_html(\"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\")[0]\n",
    "sp500['Symbol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ea489961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ATI',\n",
       " 'BF-B',\n",
       " 'BRK-B',\n",
       " 'DRE',\n",
       " 'EMBC',\n",
       " 'NLSN',\n",
       " 'PVH',\n",
       " 'STEM',\n",
       " 'SVFA',\n",
       " 'SWH',\n",
       " 'TWTR',\n",
       " 'VNT'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(nport['symbol']).difference(set(sp500['Symbol']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "47e05eb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ACGL', 'BF.B', 'BRK.B', 'CSGP', 'EQT', 'INVH', 'PCG', 'SHW', 'TRGP', 'VFC'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(sp500['Symbol']).difference(set(nport['symbol']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e21c5c",
   "metadata": {},
   "source": [
    "Not bad. The symbols `BF.B` and `BRK.B` are just different ways of representing the same symbols as `BF-B` and `BRK-B` (and are a continual pain to those of us in finance). We already know about `NLSN`. `TRGP`, `PCG`, `EQT`, `CSGP`, and `INVH` recently replaced `NLSN`, `CTXS`, `DRE`, `PVH`, and `PENN` in the index, respectively. With a little bit more manual updating, we could get to 100% accuracy.\n",
    "\n",
    "## Summary\n",
    "This article covered several techniques to match data between two data sources, using Python and pandas. We tried a simple match, some data cleanup and normalization with another match, eliminated duplicate data, then used fuzzy search. Finally, we had to do some manual verification and cleanup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5557f0d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
